{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2401</th>\n",
       "      <th>Borderlands</th>\n",
       "      <th>Positive</th>\n",
       "      <th>im getting on borderlands and i will murder you all ,</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2401  Borderlands  Positive   \n",
       "0  2401  Borderlands  Positive  \\\n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "  im getting on borderlands and i will murder you all ,  \n",
       "0  I am coming to the borders and I will kill you...     \n",
       "1  im getting on borderlands and i will kill you ...     \n",
       "2  im coming on borderlands and i will murder you...     \n",
       "3  im getting on borderlands 2 and i will murder ...     \n",
       "4  im getting into borderlands and i can murder y...     "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"twitter_training.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3364</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>Irrelevant</th>\n",
       "      <th>I mentioned on Facebook that I was struggling for motivation to go for a run the other day, which has been translated by Tom‚Äôs great auntie as ‚ÄòHayley can‚Äôt get out of bed‚Äô and told to his grandma, who now thinks I‚Äôm a lazy, terrible person ü§£</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>352</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8312</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4371</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4433</td>\n",
       "      <td>Google</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6273</td>\n",
       "      <td>FIFA</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hi @EAHelp I‚Äôve had Madeleine McCann in my cel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>4891</td>\n",
       "      <td>GrandTheftAuto(GTA)</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>‚≠êÔ∏è Toronto is the arts and culture capital of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4359</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2652</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Today sucked so it‚Äôs time to drink wine n play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>8069</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Bought a fraction of Microsoft today. Small wins.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>6960</td>\n",
       "      <td>johnson&amp;johnson</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Johnson &amp; Johnson to stop selling talc baby po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     3364             Facebook  Irrelevant   \n",
       "0     352               Amazon     Neutral  \\\n",
       "1    8312            Microsoft    Negative   \n",
       "2    4371                CS-GO    Negative   \n",
       "3    4433               Google     Neutral   \n",
       "4    6273                 FIFA    Negative   \n",
       "..    ...                  ...         ...   \n",
       "994  4891  GrandTheftAuto(GTA)  Irrelevant   \n",
       "995  4359                CS-GO  Irrelevant   \n",
       "996  2652          Borderlands    Positive   \n",
       "997  8069            Microsoft    Positive   \n",
       "998  6960      johnson&johnson     Neutral   \n",
       "\n",
       "    I mentioned on Facebook that I was struggling for motivation to go for a run the other day, which has been translated by Tom‚Äôs great auntie as ‚ÄòHayley can‚Äôt get out of bed‚Äô and told to his grandma, who now thinks I‚Äôm a lazy, terrible person ü§£  \n",
       "0    BBC News - Amazon boss Jeff Bezos rejects clai...                                                                                                                                                                                                  \n",
       "1    @Microsoft Why do I pay for WORD when it funct...                                                                                                                                                                                                  \n",
       "2    CSGO matchmaking is so full of closet hacking,...                                                                                                                                                                                                  \n",
       "3    Now the President is slapping Americans in the...                                                                                                                                                                                                  \n",
       "4    Hi @EAHelp I‚Äôve had Madeleine McCann in my cel...                                                                                                                                                                                                  \n",
       "..                                                 ...                                                                                                                                                                                                  \n",
       "994  ‚≠êÔ∏è Toronto is the arts and culture capital of ...                                                                                                                                                                                                  \n",
       "995  tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...                                                                                                                                                                                                  \n",
       "996  Today sucked so it‚Äôs time to drink wine n play...                                                                                                                                                                                                  \n",
       "997  Bought a fraction of Microsoft today. Small wins.                                                                                                                                                                                                  \n",
       "998  Johnson & Johnson to stop selling talc baby po...                                                                                                                                                                                                  \n",
       "\n",
       "[999 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"twitter_validation.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'I mentioned on Facebook that I was struggling for motivation to go for a run the other day, which has been translated by Tom‚Äôs great auntie as ‚ÄòHayley can‚Äôt get out of bed‚Äô and told to his grandma, who now thinks I‚Äôm a lazy, terrible person ü§£':'text'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3364</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>Irrelevant</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>352</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8312</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4371</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4433</td>\n",
       "      <td>Google</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6273</td>\n",
       "      <td>FIFA</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hi @EAHelp I‚Äôve had Madeleine McCann in my cel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>4891</td>\n",
       "      <td>GrandTheftAuto(GTA)</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>‚≠êÔ∏è Toronto is the arts and culture capital of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4359</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2652</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Today sucked so it‚Äôs time to drink wine n play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>8069</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Bought a fraction of Microsoft today. Small wins.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>6960</td>\n",
       "      <td>johnson&amp;johnson</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Johnson &amp; Johnson to stop selling talc baby po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     3364             Facebook  Irrelevant   \n",
       "0     352               Amazon     Neutral  \\\n",
       "1    8312            Microsoft    Negative   \n",
       "2    4371                CS-GO    Negative   \n",
       "3    4433               Google     Neutral   \n",
       "4    6273                 FIFA    Negative   \n",
       "..    ...                  ...         ...   \n",
       "994  4891  GrandTheftAuto(GTA)  Irrelevant   \n",
       "995  4359                CS-GO  Irrelevant   \n",
       "996  2652          Borderlands    Positive   \n",
       "997  8069            Microsoft    Positive   \n",
       "998  6960      johnson&johnson     Neutral   \n",
       "\n",
       "                                                  text  \n",
       "0    BBC News - Amazon boss Jeff Bezos rejects clai...  \n",
       "1    @Microsoft Why do I pay for WORD when it funct...  \n",
       "2    CSGO matchmaking is so full of closet hacking,...  \n",
       "3    Now the President is slapping Americans in the...  \n",
       "4    Hi @EAHelp I‚Äôve had Madeleine McCann in my cel...  \n",
       "..                                                 ...  \n",
       "994  ‚≠êÔ∏è Toronto is the arts and culture capital of ...  \n",
       "995  tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...  \n",
       "996  Today sucked so it‚Äôs time to drink wine n play...  \n",
       "997  Bought a fraction of Microsoft today. Small wins.  \n",
       "998  Johnson & Johnson to stop selling talc baby po...  \n",
       "\n",
       "[999 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"BBC News - Amazon boss Jeff Bezos rejects claims company acted like a 'drug dealer' bbc.co.uk/news/av/busine‚Ä¶\",\n",
       " '@Microsoft Why do I pay for WORD when it functions so poorly on my @SamsungUS Chromebook? üôÑ',\n",
       " \"CSGO matchmaking is so full of closet hacking, it's a truly awful game.\",\n",
       " 'Now the President is slapping Americans in the face that he really did commit an unlawful act after his  acquittal! From Discover on Google vanityfair.com/news/2020/02/t‚Ä¶',\n",
       " 'Hi @EAHelp I‚Äôve had Madeleine McCann in my cellar for the past 13 years and the little sneaky thing just escaped whilst I was loading up some fifa points, she took my card and I‚Äôm having to use my paypal account but it isn‚Äôt working, can you help me resolve it please?',\n",
       " 'Thank you @EAMaddenNFL!! \\n\\nNew TE Austin Hooper in the ORANGE & BROWN!! \\n\\n#Browns | @AustinHooper18 \\n\\n pic.twitter.com/GRg4xzFKOn',\n",
       " 'Rocket League, Sea of Thieves or Rainbow Six: Siegeü§î? I love playing all three on stream but which is the best? #stream #twitch #RocketLeague #SeaOfThieves #RainbowSixSiege #follow',\n",
       " 'my ass still knee-deep in Assassins Creed Odyssey with no way out anytime soon lmao',\n",
       " 'FIX IT JESUS ! Please FIX IT ! What In the world is going on here.  @PlayStation @AskPlayStation @Playstationsup @Treyarch @CallofDuty negative 345 silver wolf error code pic.twitter.com/ziRyhrf59Q',\n",
       " 'The professional dota 2 scene is fucking exploding and I completely welcome it.\\n\\nGet the garbage out.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts=[]\n",
    "for t in df['text'][0:10]:\n",
    "  texts.append(t)\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BBC', 'News', '-', 'Amazon', 'boss', 'Jeff', 'Bezos', 'rejects', 'claims', 'company', 'acted', 'like', 'a', \"'drug\", 'dealer', \"'\", 'bbc.co.uk/news/av/busine‚Ä¶']\n"
     ]
    }
   ],
   "source": [
    "tokonized_word = word_tokenize(texts[0])\n",
    "print(tokonized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"BBC News - Amazon boss Jeff Bezos rejects claims company acted like a 'drug dealer' bbc.co.uk/news/av/busine‚Ä¶\"]\n"
     ]
    }
   ],
   "source": [
    "tokennized_sent = sent_tokenize(texts[0])\n",
    "print(tokennized_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBC\n",
      "News\n",
      "-\n",
      "Amazon\n",
      "boss\n",
      "Jeff\n",
      "Bezos\n",
      "rejects\n",
      "claims\n",
      "company\n",
      "acted\n",
      "like\n",
      "'drug\n",
      "dealer\n",
      "'\n",
      "bbc.co.uk/news/av/busine‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords=stopwords.words('english')\n",
    "for i in tokonized_word:\n",
    "  if i not in stopwords:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbc\n",
      "new\n",
      "-\n",
      "amazon\n",
      "boss\n",
      "jeff\n",
      "bezo\n",
      "reject\n",
      "claim\n",
      "compani\n",
      "act\n",
      "like\n",
      "a\n",
      "'drug\n",
      "dealer\n",
      "'\n",
      "bbc.co.uk/news/av/busine‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "for i in tokonized_word:\n",
    "  print(ps.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBC-----1\n",
      "News-----1\n",
      "------1\n",
      "Amazon-----1\n",
      "boss-----1\n",
      "Jeff-----1\n",
      "Bezos-----1\n",
      "rejects-----1\n",
      "claims-----1\n",
      "company-----1\n",
      "acted-----1\n",
      "like-----1\n",
      "a-----1\n",
      "'drug-----1\n",
      "dealer-----1\n",
      "'-----1\n",
      "bbc.co.uk/news/av/busine‚Ä¶-----1\n",
      "<class 'nltk.probability.FreqDist'>\n"
     ]
    }
   ],
   "source": [
    "freqdist=nltk.FreqDist(tokonized_word)\n",
    "for i,j in freqdist.items():\n",
    "  print(f'{i}-----{j}')\n",
    "\n",
    "print(type(freqdist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBC\n",
      "News\n",
      "-\n",
      "Amazon\n",
      "boss\n",
      "Jeff\n",
      "Bezos\n",
      "reject\n",
      "claim\n",
      "company\n",
      "act\n",
      "like\n",
      "a\n",
      "'drug\n",
      "dealer\n",
      "'\n",
      "bbc.co.uk/news/av/busine‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lem=WordNetLemmatizer()\n",
    "for w in tokonized_word:\n",
    "  print(lem.lemmatize(w,pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"BBC News - Amazon boss Jeff Bezos rejects claims company acted like a 'drug dealer' bbc.co.uk/news/av/busine‚Ä¶\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokennized_sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"BBC News - Amazon boss Jeff Bezos rejects claims company acted like a 'drug dealer' bbc.co.uk/news/av/busine‚Ä¶\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = tokennized_sent[0]\n",
    "document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "tokens = document.lower().split()\n",
    "tokens\n",
    "\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'bbc': 0.0625,\n",
       "         'news': 0.0625,\n",
       "         '-': 0.0625,\n",
       "         'amazon': 0.0625,\n",
       "         'boss': 0.0625,\n",
       "         'jeff': 0.0625,\n",
       "         'bezos': 0.0625,\n",
       "         'rejects': 0.0625,\n",
       "         'claims': 0.0625,\n",
       "         'company': 0.0625,\n",
       "         'acted': 0.0625,\n",
       "         'like': 0.0625,\n",
       "         'a': 0.0625,\n",
       "         \"'drug\": 0.0625,\n",
       "         \"dealer'\": 0.0625,\n",
       "         'bbc.co.uk/news/av/busine‚Ä¶': 0.0625})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = Counter(tokens)\n",
    "for word in tf:\n",
    "    tf[word] = tf[word]/float(len(tokens))\n",
    "    \n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bbc': 0.0, 'news': 0.0, '-': 0.0, 'amazon': 0.0, 'boss': 0.0, 'jeff': 0.0, 'bezos': 0.0, 'rejects': 0.0, 'claims': 0.0, 'company': 0.0, 'acted': 0.0, 'like': 0.0, 'a': 0.0, \"'drug\": 0.0, \"dealer'\": 0.0, 'bbc.co.uk/news/av/busine‚Ä¶': 0.0}\n"
     ]
    }
   ],
   "source": [
    "def calculate_idf(word, documents):\n",
    "    n = len([True for document in documents if word in document])\n",
    "    return math.log(len(documents)/n)\n",
    "\n",
    "idf = {}\n",
    "for word in tf:\n",
    "    idf[word] = calculate_idf(word, [tokens])\n",
    "\n",
    "# calculate the TF-IDF score of each word\n",
    "tf_idf = {}\n",
    "for word in tf:\n",
    "    tf_idf[word] = tf[word] * idf[word]\n",
    "\n",
    "# print the TF-IDF representation of the document\n",
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize document\n",
    "document = tokennized_sent[0]\n",
    "\n",
    "tokens = word_tokenize(document.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original document:  The quick brown fox jumps over the lazy dog. Dogs are known to be loyal and friendly companions.\n",
      "Tokenized document:  ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.', 'dogs', 'are', 'known', 'to', 'be', 'loyal', 'and', 'friendly', 'companions', '.']\n",
      "Filtered document:  ['quick', 'brown', 'fox', 'jumps', 'lazy', 'dog', '.', 'dogs', 'known', 'loyal', 'friendly', 'companions', '.']\n",
      "POS tags:  [('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'NNS'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.'), ('dogs', 'NNS'), ('known', 'VBN'), ('loyal', 'JJ'), ('friendly', 'JJ'), ('companions', 'NNS'), ('.', '.')]\n",
      "Stemmed document:  ['quick', 'brown', 'fox', 'jump', 'lazi', 'dog', '.', 'dog', 'known', 'loyal', 'friendli', 'companion', '.']\n",
      "Lemmatized document:  ['quick', 'brown', 'fox', 'jump', 'lazy', 'dog', '.', 'dog', 'known', 'loyal', 'friendly', 'companion', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# sample document\n",
    "document = \"The quick brown fox jumps over the lazy dog. Dogs are known to be loyal and friendly companions.\"\n",
    "\n",
    "# tokenize the document\n",
    "tokens = word_tokenize(document.lower())\n",
    "\n",
    "# remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "# perform part-of-speech (POS) tagging\n",
    "pos_tags = pos_tag(filtered_tokens)\n",
    "\n",
    "# perform stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "\n",
    "# perform lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "# print the results\n",
    "print(\"Original document: \", document)\n",
    "print(\"Tokenized document: \", tokens)\n",
    "print(\"Filtered document: \", filtered_tokens)\n",
    "print(\"POS tags: \", pos_tags)\n",
    "print(\"Stemmed document: \", stemmed_tokens)\n",
    "print(\"Lemmatized document: \", lemmatized_tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
